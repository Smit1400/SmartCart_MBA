{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from io import StringIO\n",
    "import sys\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_agent_executor\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "from typing import Annotated, Any, Dict, Optional, Sequence, TypedDict, List, Tuple\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "import operator\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_core.tools import tool\n",
    "import random\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.agents import AgentFinish\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] =\"multi-agent\"\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, \n",
    "                          max_tokens=1024,\n",
    "    model_name=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SmartCart_MBA\\streamlit_app\\venv\\lib\\site-packages\\langchain_experimental\\agents\\agent_toolkits\\pandas\\base.py:242: UserWarning: Received additional kwargs {'stop': ['\\nObservation:'], 'handle_parsing_errors': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path= 'data.csv'\n",
    "\n",
    "csv_agent= create_csv_agent(\n",
    "        ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "        file_path, \n",
    "        verbose=True,\n",
    "        stop=[\"\\nObservation:\"],\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "        handle_parsing_errors=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"insights\", return_direct=False)\n",
    "def get_actionable_insights(input: str):\n",
    "    \"\"\"Return actionable business insights from the dataset either for a country or the whole dataset\"\"\"\n",
    "    question = f\"Give me actionable business insights for {input}\"\n",
    "    prompt = \"\"\"\n",
    "        Given a specific country or the entire dataset, generate actionable business insights, including but not limited to overall revenue, top-selling product, customer with the highest number of purchases, and the most popular product in the current period.\n",
    "    \"\"\"\n",
    "    insights = csv_agent.run(prompt)\n",
    "    return insights\n",
    "    \n",
    "@tool('chart_pdf', return_direct=False)\n",
    "def get_charts_pdf(input: str):\n",
    "    \"\"\"Returns python executable code that first loads data.csv and generates a pdf with charts\"\"\"\n",
    "    question = f\"Give me a detailed report for {input}\"\n",
    "\n",
    "    prompt = \"\"\" Generate Python code that creates a comprehensive series of graphs to analyze business data for country. Also include the code for loading the data (data.csv)\n",
    "    The visualization should potentially include, but not be limited to, a bar plot of the top-selling products, a line plot showing sales trends over time, and a pie chart detailing the sales distribution among top customers. \n",
    "    Additionally, consider including other relevant analyses such as sales by category, regional sales distribution, and seasonality effects on sales, if the data permits. \n",
    "\n",
    "    The graphs should be stored in a PDF named 'sales_report.pdf'. Utilize pandas for data handling, matplotlib for plotting, and the matplotlib.backends.backend_pdf module for generating the PDF file. \n",
    "    The code should be well-commented to explain the purpose of each graph and how it contributes to understanding the business climate in `country_name`. Include brief insights or interpretations for each plot to highlight the key takeaways and business implications derived from the data analysis.\n",
    "    \"\"\"  + question\n",
    "    charts = csv_agent.run(prompt)\n",
    "    charts = charts.split(\"python\")[1].split('```')[0]\n",
    "    exec(charts)\n",
    "    return charts\n",
    "\n",
    "tools = [get_actionable_insights, get_charts_pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    messages = state['messages']\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
    "    )\n",
    "    print(f\"The agent action is {action}\")\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    print(f\"The tool result is: {response}\")\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    \n",
    "    should_continue,\n",
    "    \n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent action is tool='insights' tool_input={'input': 'france'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Revenue'] = df['Price'] * df['Quantity']\"}`\n",
      "responded: Sure, let's start by calculating the overall revenue. We can do this by multiplying the `Price` by the `Quantity` for each transaction and then summing up the results.\n",
      "\n",
      "Let's create a new column `Revenue` in the dataframe.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"total_revenue = df['Revenue'].sum()\\ntotal_revenue\"}`\n",
      "responded: Now, let's calculate the overall revenue.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m60280024.26000001\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"top_selling_product = df.groupby('ProductName')['Quantity'].sum().idxmax()\\ntop_selling_product\"}`\n",
      "responded: The total revenue from all transactions is approximately $60,280,024.26.\n",
      "\n",
      "Next, let's find the top-selling product. We can do this by grouping the data by `ProductName` and summing the `Quantity` for each product. The product with the highest sum is the top-selling product.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPopcorn Holder\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"top_customer = df.groupby('CustomerNo')['Quantity'].sum().idxmax()\\ntop_customer\"}`\n",
      "responded: The top-selling product is the \"Popcorn Holder\".\n",
      "\n",
      "Now, let's find the customer with the highest number of purchases. We can do this by grouping the data by `CustomerNo` and summing the `Quantity` for each customer. The customer with the highest sum has made the most purchases.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m14646.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"most_popular_product_current_period = df[df['Date'] == '12/9/2019'].groupby('ProductName')['Quantity'].sum().idxmax()\\nmost_popular_product_current_period\"}`\n",
      "responded: The customer with the highest number of purchases is the one with the customer number 14646.\n",
      "\n",
      "Finally, let's find the most popular product in the current period. We can do this by filtering the data for the current period (in this case, let's assume the current period is '12/9/2019'), grouping by `ProductName`, and summing the `Quantity` for each product. The product with the highest sum is the most popular product in the current period.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSmall Folding Scissor(Pointed Edge)\u001b[0m\u001b[32;1m\u001b[1;3mThe most popular product on '12/9/2019' is the \"Small Folding Scissor(Pointed Edge)\".\n",
      "\n",
      "To summarize:\n",
      "\n",
      "- The total revenue from all transactions is approximately $60,280,024.26.\n",
      "- The top-selling product is the \"Popcorn Holder\".\n",
      "- The customer with the highest number of purchases is the one with the customer number 14646.\n",
      "- The most popular product on '12/9/2019' is the \"Small Folding Scissor(Pointed Edge)\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The tool result is: The most popular product on '12/9/2019' is the \"Small Folding Scissor(Pointed Edge)\".\n",
      "\n",
      "To summarize:\n",
      "\n",
      "- The total revenue from all transactions is approximately $60,280,024.26.\n",
      "- The top-selling product is the \"Popcorn Holder\".\n",
      "- The customer with the highest number of purchases is the one with the customer number 14646.\n",
      "- The most popular product on '12/9/2019' is the \"Small Folding Scissor(Pointed Edge)\".\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
    "\n",
    "system_message = SystemMessage(content=\"you are a helpful assistant\")\n",
    "user_01 = HumanMessage(content=\"Give insights for france\")\n",
    "\n",
    "inputs = {\"messages\": [system_message,user_01]}\n",
    "\n",
    "result = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a helpful assistant'),\n",
       " HumanMessage(content='Give insights for france'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"input\": \"france\"\\n}', 'name': 'insights'}}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 109, 'total_tokens': 125}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}),\n",
       " FunctionMessage(content='The most popular product on \\'12/9/2019\\' is the \"Small Folding Scissor(Pointed Edge)\".\\n\\nTo summarize:\\n\\n- The total revenue from all transactions is approximately $60,280,024.26.\\n- The top-selling product is the \"Popcorn Holder\".\\n- The customer with the highest number of purchases is the one with the customer number 14646.\\n- The most popular product on \\'12/9/2019\\' is the \"Small Folding Scissor(Pointed Edge)\".', name='insights'),\n",
       " AIMessage(content='Here are some insights for France:\\n\\n- The total revenue from all transactions is approximately $60,280,024.26.\\n- The top-selling product is the \"Popcorn Holder\".\\n- The customer with the highest number of purchases is the one with the customer number 14646.\\n- The most popular product on \\'12/9/2019\\' is the \"Small Folding Scissor(Pointed Edge)\".', response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 236, 'total_tokens': 319}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some insights for France:\n",
      "\n",
      "- The total revenue from all transactions is approximately $60,280,024.26.\n",
      "- The top-selling product is the \"Popcorn Holder\".\n",
      "- The customer with the highest number of purchases is the one with the customer number 14646.\n",
      "- The most popular product on '12/9/2019' is the \"Small Folding Scissor(Pointed Edge)\".\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
